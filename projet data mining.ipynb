{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this work is to analyse transcripts and do comparisons between transcripts of adjacent quarters.\n",
    "\n",
    "In order to do that we use 3 methods:\n",
    "    1. Fuzzy Wuzzy: Implement a transcript summary utility that compares one transcript to the previous one and lists the major differences between the quarters.\n",
    "    \n",
    "    2. Topics Modelling: What are new things that happened this quarter and didn't happen in the previous one. What things happened in the previous quarter and didn't happen in this one. \n",
    "    \n",
    "    3. Give a sentiment score to each transcript with Mc Donald Loughran Lexicon, Vader and Text Blob.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FS2017-FS2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from flashtext import KeywordProcessor\n",
    "pos_keyword_processor = KeywordProcessor()\n",
    "neg_keyword_processor = KeywordProcessor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs2018 = pd.read_csv('FS2018.csv',encoding='utf-8')\n",
    "fs2017 = pd.read_csv('FS2017.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13371"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fs2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I append the transcripts of 2017 to the file of 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs2018=fs2018.append(fs2017,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs2018[['Indicator','Ticker']] = fs2018.ticker.str.split(\":\",expand=True)\n",
    "indexNames = fs2018[fs2018['Indicator']== 'EXCH' ].index\n",
    "# Delete these row indexes from dataFrame\n",
    "fs2018.drop(indexNames , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs2018 = fs2018.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>article_date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_source</th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_title</th>\n",
       "      <th>organization_name</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>IUS.XX9</td>\n",
       "      <td>2018-01-03 15:00:00|2018-01-03 15:53:05</td>\n",
       "      <td>2026528</td>\n",
       "      <td>Q1 2018 Earnings Call - 2026528 : 904708104</td>\n",
       "      <td>ALL TEXT IS RELEVANT\\r\\n\\r\\nLadies and gentlem...</td>\n",
       "      <td>Q1 2018 Earnings Call</td>\n",
       "      <td>UniFirst Corp.</td>\n",
       "      <td>US:IUS.XX9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>UNF</td>\n",
       "      <td>2018-01-03 15:00:00|2018-01-03 15:53:05</td>\n",
       "      <td>2026528</td>\n",
       "      <td>Q1 2018 Earnings Call - 2026528 : 904708104</td>\n",
       "      <td>ALL TEXT IS RELEVANT\\r\\n\\r\\nLadies and gentlem...</td>\n",
       "      <td>Q1 2018 Earnings Call</td>\n",
       "      <td>UniFirst Corp.</td>\n",
       "      <td>US:UNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>VERU</td>\n",
       "      <td>2018-01-05 13:00:00|2018-01-05 21:23:05</td>\n",
       "      <td>2029277</td>\n",
       "      <td>Q4 2017 Earnings Call - 2029277 : 92536C103</td>\n",
       "      <td>ALL TEXT IS RELEVANT\\r\\n\\r\\nGood morning, ladi...</td>\n",
       "      <td>Q4 2017 Earnings Call</td>\n",
       "      <td>Veru, Inc.</td>\n",
       "      <td>US:VERU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GB</td>\n",
       "      <td>MCRO</td>\n",
       "      <td>2018-01-08 09:00:00|2018-01-08 10:48:49</td>\n",
       "      <td>2021320</td>\n",
       "      <td>Q2 2018 Earnings Call - 2021320 : G6117L186</td>\n",
       "      <td>ALL TEXT IS RELEVANT\\r\\n\\r\\nGood morning every...</td>\n",
       "      <td>Q2 2018 Earnings Call</td>\n",
       "      <td>Micro Focus International Plc</td>\n",
       "      <td>GB:MCRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CA</td>\n",
       "      <td>EXF</td>\n",
       "      <td>2018-01-09 22:00:00|2018-01-09 23:42:39</td>\n",
       "      <td>2024627</td>\n",
       "      <td>Q1 2018 Earnings Call - 2024627 : 302046107</td>\n",
       "      <td>ALL TEXT IS RELEVANT\\r\\n\\r\\nGood day and welco...</td>\n",
       "      <td>Q1 2018 Earnings Call</td>\n",
       "      <td>EXFO, Inc.</td>\n",
       "      <td>CA:EXF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Indicator   Ticker                             article_date  article_id  \\\n",
       "0        US  IUS.XX9  2018-01-03 15:00:00|2018-01-03 15:53:05     2026528   \n",
       "1        US      UNF  2018-01-03 15:00:00|2018-01-03 15:53:05     2026528   \n",
       "2        US     VERU  2018-01-05 13:00:00|2018-01-05 21:23:05     2029277   \n",
       "3        GB     MCRO  2018-01-08 09:00:00|2018-01-08 10:48:49     2021320   \n",
       "4        CA      EXF  2018-01-09 22:00:00|2018-01-09 23:42:39     2024627   \n",
       "\n",
       "                                article_source  \\\n",
       "0  Q1 2018 Earnings Call - 2026528 : 904708104   \n",
       "1  Q1 2018 Earnings Call - 2026528 : 904708104   \n",
       "2  Q4 2017 Earnings Call - 2029277 : 92536C103   \n",
       "3  Q2 2018 Earnings Call - 2021320 : G6117L186   \n",
       "4  Q1 2018 Earnings Call - 2024627 : 302046107   \n",
       "\n",
       "                                        article_text          article_title  \\\n",
       "0  ALL TEXT IS RELEVANT\\r\\n\\r\\nLadies and gentlem...  Q1 2018 Earnings Call   \n",
       "1  ALL TEXT IS RELEVANT\\r\\n\\r\\nLadies and gentlem...  Q1 2018 Earnings Call   \n",
       "2  ALL TEXT IS RELEVANT\\r\\n\\r\\nGood morning, ladi...  Q4 2017 Earnings Call   \n",
       "3  ALL TEXT IS RELEVANT\\r\\n\\r\\nGood morning every...  Q2 2018 Earnings Call   \n",
       "4  ALL TEXT IS RELEVANT\\r\\n\\r\\nGood day and welco...  Q1 2018 Earnings Call   \n",
       "\n",
       "               organization_name      ticker  \n",
       "0                 UniFirst Corp.  US:IUS.XX9  \n",
       "1                 UniFirst Corp.      US:UNF  \n",
       "2                     Veru, Inc.     US:VERU  \n",
       "3  Micro Focus International Plc     GB:MCRO  \n",
       "4                     EXFO, Inc.      CA:EXF  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I remove all the stopwords to compare in more efficient manner further the transcripts of adjacent quarters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def clean_string(text):\n",
    "    #text=''.join([word for word in text if word not in string.punctuation])\n",
    "    #text=text.lower()\n",
    "    text=' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "fs2018['article_text'] = fs2018['article_text'].apply(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('mypickle.pickle', 'wb') as f:\n",
    "    pickle.dump(fs2018, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary transcript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrange the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I arrange the data to compare the adjacent quarters later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         IUS.XX9  \\\n",
      "article_title                                                      \n",
      "Q1 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q2 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q3 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q4 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q1 2018        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q2 2018        ALL TEXT IS RELEVANT Welcome second quarter ea...   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                             UNF  \\\n",
      "article_title                                                      \n",
      "Q1 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q2 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q3 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q4 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q1 2018        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q2 2018        ALL TEXT IS RELEVANT Welcome second quarter ea...   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                            VERU  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017        ALL TEXT IS RELEVANT [Abrupt Start] gentlemen ...   \n",
      "Q3 2017        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
      "Q4 2017        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
      "Q1 2018        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
      "Q2 2018                                                      NaN   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                            MCRO  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017                                                      NaN   \n",
      "Q3 2017                                                      NaN   \n",
      "Q4 2017        ALL TEXT IS RELEVANT Good morning, everyone. T...   \n",
      "Q1 2018                                                      NaN   \n",
      "Q2 2018        ALL TEXT IS RELEVANT Good morning everyone wel...   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                             EXF  \\\n",
      "article_title                                                      \n",
      "Q1 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q2 2017        ALL TEXT IS RELEVANT Good day welcome EXFO's S...   \n",
      "Q3 2017        ALL TEXT IS RELEVANT Please stand by. Good day...   \n",
      "Q4 2017        ALL TEXT IS RELEVANT Good day welcome EXFO's F...   \n",
      "Q1 2018        ALL TEXT IS RELEVANT Good day welcome EXFO's F...   \n",
      "Q2 2018        ALL TEXT IS RELEVANT Good day everyone welcome...   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                            DUST  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q3 2017        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
      "Q4 2017        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
      "Q1 2018        ALL TEXT IS RELEVANT Thank standing by, ladies...   \n",
      "Q2 2018        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                             SZU  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017                                                      NaN   \n",
      "Q3 2017        ALL TEXT IS RELEVANT Thank good morning everyb...   \n",
      "Q4 2017        ALL TEXT IS RELEVANT Thank you, good afternoon...   \n",
      "Q1 2018        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
      "Q2 2018        ALL TEXT IS RELEVANT Thank good morning, ladie...   \n",
      "Q3 2018        ALL TEXT IS RELEVANT Ladies gentlemen, I wish ...   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                          532187  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017                                                      NaN   \n",
      "Q3 2017        ALL TEXT IS RELEVANT Ladies gentlemen, good da...   \n",
      "Q4 2017        ALL TEXT IS RELEVANT Good afternoon. Thank joi...   \n",
      "Q1 2018        ALL TEXT IS RELEVANT Ladies gentlemen, good da...   \n",
      "Q2 2018        ALL TEXT IS RELEVANT [Abrupt Start] ...especia...   \n",
      "Q3 2018        ALL TEXT IS RELEVANT Ladies gentlemen, good da...   \n",
      "Q4 2018        ALL TEXT IS RELEVANT Ladies gentlemen, good da...   \n",
      "\n",
      "                                                            8905  \\\n",
      "article_title                                                      \n",
      "Q1 2017        ALL TEXT IS RELEVANT I Umeda, General Manager ...   \n",
      "Q2 2017        ALL TEXT IS RELEVANT I Yoshida AEON MALL. Than...   \n",
      "Q3 2017        ALL TEXT IS RELEVANT [Abrupt Start] Now I talk...   \n",
      "Q4 2017                                                      NaN   \n",
      "Q1 2018                                                      NaN   \n",
      "Q2 2018                                                      NaN   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                           ABFLA  ...  \\\n",
      "article_title                                                     ...   \n",
      "Q1 2017        ALL TEXT IS RELEVANT Good morning. My name Reg...  ...   \n",
      "Q2 2017        ALL TEXT IS RELEVANT Good morning. My name Reg...  ...   \n",
      "Q3 2017        ALL TEXT IS RELEVANT Good morning. My name Reg...  ...   \n",
      "Q4 2017        ALL TEXT IS RELEVANT Good morning. My name Reg...  ...   \n",
      "Q1 2018        ALL TEXT IS RELEVANT Good morning. My name Reg...  ...   \n",
      "Q2 2018                                                      NaN  ...   \n",
      "Q3 2018                                                      NaN  ...   \n",
      "Q4 2018                                                      NaN  ...   \n",
      "\n",
      "                                                            MXFC  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017                                                      NaN   \n",
      "Q3 2017                                                      NaN   \n",
      "Q4 2017        ALL TEXT IS RELEVANT I think 9:30 kick then. T...   \n",
      "Q1 2018                                                      NaN   \n",
      "Q2 2018                                                      NaN   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                          540702  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017                                                      NaN   \n",
      "Q3 2017                                                      NaN   \n",
      "Q4 2017                                                      NaN   \n",
      "Q1 2018                                                      NaN   \n",
      "Q2 2018        ALL TEXT IS RELEVANT Ladies gentlemen, good da...   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                             EEI  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017                                                      NaN   \n",
      "Q3 2017                                                      NaN   \n",
      "Q4 2017                                                      NaN   \n",
      "Q1 2018        ALL TEXT IS RELEVANT Good afternoon, welcome E...   \n",
      "Q2 2018                                                      NaN   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                            PURP  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017                                                      NaN   \n",
      "Q3 2017                                                      NaN   \n",
      "Q4 2017                                                      NaN   \n",
      "Q1 2018                                                      NaN   \n",
      "Q2 2018        ALL TEXT IS RELEVANT Okay. Good morning, every...   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                          531092  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017                                                      NaN   \n",
      "Q3 2017                                                      NaN   \n",
      "Q4 2017                                                      NaN   \n",
      "Q1 2018                                                      NaN   \n",
      "Q2 2018        ALL TEXT IS RELEVANT Ladies gentlemen, good da...   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                             ACR  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
      "Q3 2017                                                      NaN   \n",
      "Q4 2017                                                      NaN   \n",
      "Q1 2018                                                      NaN   \n",
      "Q2 2018                                                      NaN   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                            TXCL  \\\n",
      "article_title                                                      \n",
      "Q1 2017                                                      NaN   \n",
      "Q2 2017        ALL TEXT IS RELEVANT Ladies gentlemen, welcome...   \n",
      "Q3 2017                                                      NaN   \n",
      "Q4 2017                                                      NaN   \n",
      "Q1 2018                                                      NaN   \n",
      "Q2 2018                                                      NaN   \n",
      "Q3 2018                                                      NaN   \n",
      "Q4 2018                                                      NaN   \n",
      "\n",
      "                                                             SKO MYDX CLNV  \n",
      "article_title                                                               \n",
      "Q1 2017                                                      NaN  NaN  NaN  \n",
      "Q2 2017                                                      NaN  NaN  NaN  \n",
      "Q3 2017                                                      NaN  NaN  NaN  \n",
      "Q4 2017                                                      NaN  NaN  NaN  \n",
      "Q1 2018                                                      NaN  NaN  NaN  \n",
      "Q2 2018        ALL TEXT IS RELEVANT Good day, welcome Serko L...  NaN  NaN  \n",
      "Q3 2018                                                      NaN  NaN  NaN  \n",
      "Q4 2018                                                      NaN  NaN  NaN  \n",
      "\n",
      "[8 rows x 7840 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(\"mypickle.pickle\", \"rb\") as f:\n",
    "    fs2018 = pickle.load(f)\n",
    "\n",
    "fs2018['article_title'] = fs2018['article_title'].str[:7]\n",
    "# dropping ALL duplicte values \n",
    "fs2018.drop_duplicates(subset =[\"article_title\",\"Ticker\"], \n",
    "                     keep = 'last', inplace = True) \n",
    "\n",
    "\n",
    "    \n",
    "data = np.array([['article_title'],\n",
    "                ['Q1 2017'],\n",
    "                ['Q2 2017'],\n",
    "                ['Q3 2017'],\n",
    "                ['Q4 2017'],\n",
    "                ['Q1 2018'],\n",
    "                ['Q2 2018'],\n",
    "                ['Q3 2018'],\n",
    "                ['Q4 2018'],\n",
    "                ])\n",
    "                \n",
    "main_df=pd.DataFrame(data=data[1:,:],\n",
    "                  columns=data[0,:])\n",
    "\n",
    "\n",
    "fs2018.drop(['organization_name', 'ticker', 'article_id', 'article_source', 'article_date','Indicator'], 1, inplace=True)\n",
    "fs2018.dropna()\n",
    "\n",
    "tickers = fs2018['Ticker'].unique().tolist()\n",
    "\n",
    "\n",
    "\n",
    "for tick in tickers:\n",
    "   \n",
    "    df = fs2018.loc[fs2018.Ticker==tick]\n",
    "\n",
    "    df.rename(columns={'article_text': tick}, inplace=True)\n",
    "    \n",
    "    df.drop(['Ticker'], 1, inplace=True)\n",
    "   \n",
    "  \n",
    "    main_df= pd.merge(main_df , df, on='article_title',how='left')\n",
    "    \n",
    "\n",
    "\n",
    "main_df.set_index('article_title', inplace=True)\n",
    "print(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Earning-Quarter.pickle', 'wb') as f:\n",
    "    pickle.dump(main_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUZZY WUZZY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the method FUZZY WUZZY to detect similar sentence and then get the difference between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilan avraham\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first preprocess my data by stemmatizing and lematizing the words of each transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    " \n",
    "# init stemmer\n",
    "porter_stemmer=PorterStemmer()\n",
    " \n",
    "# Init the Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def my_cool_preprocessor(text):\n",
    "    \n",
    "    text=text.lower() \n",
    "    text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
    "    text=re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" _connector_ \",text) # normalize certain words\n",
    "\n",
    "    # stem words\n",
    "    words=re.split(\"\\\\s+\",text)\n",
    "    stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
    "    lematized_words=[lemmatizer.lemmatize(word=word) for word in stemmed_words]\n",
    "    return ' '.join(lematized_words)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I compare all the sentence in adjacent quarter that have a ratio of similarity higher than 70% and more than 10 characters.\n",
    "(To avoid the sentences like \"Yeah.\", \"Good morning.\")\n",
    "\n",
    "Then I get 4 set:\n",
    "    \n",
    "    1. Words that appears in this quarter but not in the previous one.\n",
    "    2. Numbers that appears in this quarter but not in the previous one.\n",
    "    1. Words that appears in the previous quarter but not in the current one.\n",
    "    1. Numbers that appears in this quarter but not in the current one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_names(previous_Q,follow_Q):\n",
    "    \n",
    "    ratio_array=[]\n",
    "    followQ_words=set()\n",
    "    followQ_numerical=set()\n",
    "    previousQ_numerical=set()\n",
    "    previousQ_words=set()\n",
    "\n",
    "    for row_p in previous_Q:\n",
    "        for row_f in follow_Q:\n",
    "            sort_ratio=fuzz.token_sort_ratio(row_p, row_f)\n",
    "            if len(row_p)>10 and  len(row_f)>10 and sort_ratio>70:\n",
    "               ratio_array.append((row_p,row_f,sort_ratio))\n",
    "            \n",
    "               elem1 = set(my_cool_preprocessor(row_p).split(' '))\n",
    "               elem2 = set(my_cool_preprocessor(row_f).split(' '))\n",
    "             \n",
    "               for item in elem1:\n",
    "                    if item not in elem2 and len(item)>2 and not item.isdigit():\n",
    "                        previousQ_words.add(item)\n",
    "                    elif item not in elem2 and item.isdigit():\n",
    "                        previousQ_numerical.add(item)\n",
    "            \n",
    "               for item in elem2:\n",
    "                    if item not in elem1 and len(item)>2 and not item.isdigit():\n",
    "                        followQ_words.add(item)\n",
    "                    elif item not in elem1 and item.isdigit():\n",
    "                        followQ_numerical.add(item)\n",
    "             \n",
    "             \n",
    "              \n",
    "    return followQ_words,followQ_numerical,previousQ_numerical,previousQ_words\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IUS.XX9</th>\n",
       "      <th>UNF</th>\n",
       "      <th>VERU</th>\n",
       "      <th>MCRO</th>\n",
       "      <th>EXF</th>\n",
       "      <th>DUST</th>\n",
       "      <th>SZU</th>\n",
       "      <th>532187</th>\n",
       "      <th>8905</th>\n",
       "      <th>ABFLA</th>\n",
       "      <th>...</th>\n",
       "      <th>MXFC</th>\n",
       "      <th>540702</th>\n",
       "      <th>EEI</th>\n",
       "      <th>PURP</th>\n",
       "      <th>531092</th>\n",
       "      <th>ACR</th>\n",
       "      <th>TXCL</th>\n",
       "      <th>SKO</th>\n",
       "      <th>MYDX</th>\n",
       "      <th>CLNV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Q1 2017</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL TEXT IS RELEVANT I Umeda, General Manager ...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning. My name Reg...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q2 2017</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>ALL TEXT IS RELEVANT [Abrupt Start] gentlemen ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good day welcome EXFO's S...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL TEXT IS RELEVANT I Yoshida AEON MALL. Than...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning. My name Reg...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, welcome...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q3 2017</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning, ladies gent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL TEXT IS RELEVANT Please stand by. Good day...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning, ladies gent...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Thank good morning everyb...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, good da...</td>\n",
       "      <td>ALL TEXT IS RELEVANT [Abrupt Start] Now I talk...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning. My name Reg...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q4 2017</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning, ladies gent...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning, everyone. T...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good day welcome EXFO's F...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning, ladies gent...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Thank you, good afternoon...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good afternoon. Thank joi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning. My name Reg...</td>\n",
       "      <td>...</td>\n",
       "      <td>ALL TEXT IS RELEVANT I think 9:30 kick then. T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q1 2018</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning, ladies gent...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good day welcome EXFO's F...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Thank standing by, ladies...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning, ladies gent...</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, good da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning. My name Reg...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good afternoon, welcome E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7840 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         IUS.XX9  \\\n",
       "article_title                                                      \n",
       "Q1 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q2 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q3 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q4 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q1 2018        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "\n",
       "                                                             UNF  \\\n",
       "article_title                                                      \n",
       "Q1 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q2 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q3 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q4 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q1 2018        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "\n",
       "                                                            VERU  \\\n",
       "article_title                                                      \n",
       "Q1 2017                                                      NaN   \n",
       "Q2 2017        ALL TEXT IS RELEVANT [Abrupt Start] gentlemen ...   \n",
       "Q3 2017        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
       "Q4 2017        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
       "Q1 2018        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
       "\n",
       "                                                            MCRO  \\\n",
       "article_title                                                      \n",
       "Q1 2017                                                      NaN   \n",
       "Q2 2017                                                      NaN   \n",
       "Q3 2017                                                      NaN   \n",
       "Q4 2017        ALL TEXT IS RELEVANT Good morning, everyone. T...   \n",
       "Q1 2018                                                      NaN   \n",
       "\n",
       "                                                             EXF  \\\n",
       "article_title                                                      \n",
       "Q1 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q2 2017        ALL TEXT IS RELEVANT Good day welcome EXFO's S...   \n",
       "Q3 2017        ALL TEXT IS RELEVANT Please stand by. Good day...   \n",
       "Q4 2017        ALL TEXT IS RELEVANT Good day welcome EXFO's F...   \n",
       "Q1 2018        ALL TEXT IS RELEVANT Good day welcome EXFO's F...   \n",
       "\n",
       "                                                            DUST  \\\n",
       "article_title                                                      \n",
       "Q1 2017                                                      NaN   \n",
       "Q2 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q3 2017        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
       "Q4 2017        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
       "Q1 2018        ALL TEXT IS RELEVANT Thank standing by, ladies...   \n",
       "\n",
       "                                                             SZU  \\\n",
       "article_title                                                      \n",
       "Q1 2017                                                      NaN   \n",
       "Q2 2017                                                      NaN   \n",
       "Q3 2017        ALL TEXT IS RELEVANT Thank good morning everyb...   \n",
       "Q4 2017        ALL TEXT IS RELEVANT Thank you, good afternoon...   \n",
       "Q1 2018        ALL TEXT IS RELEVANT Good morning, ladies gent...   \n",
       "\n",
       "                                                          532187  \\\n",
       "article_title                                                      \n",
       "Q1 2017                                                      NaN   \n",
       "Q2 2017                                                      NaN   \n",
       "Q3 2017        ALL TEXT IS RELEVANT Ladies gentlemen, good da...   \n",
       "Q4 2017        ALL TEXT IS RELEVANT Good afternoon. Thank joi...   \n",
       "Q1 2018        ALL TEXT IS RELEVANT Ladies gentlemen, good da...   \n",
       "\n",
       "                                                            8905  \\\n",
       "article_title                                                      \n",
       "Q1 2017        ALL TEXT IS RELEVANT I Umeda, General Manager ...   \n",
       "Q2 2017        ALL TEXT IS RELEVANT I Yoshida AEON MALL. Than...   \n",
       "Q3 2017        ALL TEXT IS RELEVANT [Abrupt Start] Now I talk...   \n",
       "Q4 2017                                                      NaN   \n",
       "Q1 2018                                                      NaN   \n",
       "\n",
       "                                                           ABFLA  ...  \\\n",
       "article_title                                                     ...   \n",
       "Q1 2017        ALL TEXT IS RELEVANT Good morning. My name Reg...  ...   \n",
       "Q2 2017        ALL TEXT IS RELEVANT Good morning. My name Reg...  ...   \n",
       "Q3 2017        ALL TEXT IS RELEVANT Good morning. My name Reg...  ...   \n",
       "Q4 2017        ALL TEXT IS RELEVANT Good morning. My name Reg...  ...   \n",
       "Q1 2018        ALL TEXT IS RELEVANT Good morning. My name Reg...  ...   \n",
       "\n",
       "                                                            MXFC 540702  \\\n",
       "article_title                                                             \n",
       "Q1 2017                                                      NaN    NaN   \n",
       "Q2 2017                                                      NaN    NaN   \n",
       "Q3 2017                                                      NaN    NaN   \n",
       "Q4 2017        ALL TEXT IS RELEVANT I think 9:30 kick then. T...    NaN   \n",
       "Q1 2018                                                      NaN    NaN   \n",
       "\n",
       "                                                             EEI PURP 531092  \\\n",
       "article_title                                                                  \n",
       "Q1 2017                                                      NaN  NaN    NaN   \n",
       "Q2 2017                                                      NaN  NaN    NaN   \n",
       "Q3 2017                                                      NaN  NaN    NaN   \n",
       "Q4 2017                                                      NaN  NaN    NaN   \n",
       "Q1 2018        ALL TEXT IS RELEVANT Good afternoon, welcome E...  NaN    NaN   \n",
       "\n",
       "                                                             ACR  \\\n",
       "article_title                                                      \n",
       "Q1 2017                                                      NaN   \n",
       "Q2 2017        ALL TEXT IS RELEVANT Ladies gentlemen, thank s...   \n",
       "Q3 2017                                                      NaN   \n",
       "Q4 2017                                                      NaN   \n",
       "Q1 2018                                                      NaN   \n",
       "\n",
       "                                                            TXCL  SKO MYDX  \\\n",
       "article_title                                                                \n",
       "Q1 2017                                                      NaN  NaN  NaN   \n",
       "Q2 2017        ALL TEXT IS RELEVANT Ladies gentlemen, welcome...  NaN  NaN   \n",
       "Q3 2017                                                      NaN  NaN  NaN   \n",
       "Q4 2017                                                      NaN  NaN  NaN   \n",
       "Q1 2018                                                      NaN  NaN  NaN   \n",
       "\n",
       "              CLNV  \n",
       "article_title       \n",
       "Q1 2017        NaN  \n",
       "Q2 2017        NaN  \n",
       "Q3 2017        NaN  \n",
       "Q4 2017        NaN  \n",
       "Q1 2018        NaN  \n",
       "\n",
       "[5 rows x 7840 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"Earning-Quarter.pickle\", \"rb\") as f:\n",
    "    sum_transcript = pickle.load(f)\n",
    "    sum_transcript.dropna(axis='columns',how=\"all\")\n",
    "    \n",
    "\n",
    "with open(\"Earning-Quarter.pickle\", \"rb\") as f:\n",
    "    main_df= pickle.load(f)\n",
    "    main_df.dropna(axis='columns',how=\"all\")\n",
    "    \n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I summarize all the information in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "for col in main_df.columns[:10]:\n",
    "    for row in range(1,main_df.shape[0]):\n",
    "  \n",
    "        if pd.isnull(main_df[col][row])==False and pd.isnull(main_df[col][row-1])==False:\n",
    "            previous_Q=sent_tokenize(\n",
    "                main_df[col][row-1])\n",
    "            follow_Q=sent_tokenize(main_df[col][row])\n",
    "        \n",
    "            solution=match_names(previous_Q, follow_Q)\n",
    "            sum_transcript.at[main_df.index[row-1],'{} Summary quarter'.format(col)]=' '.join(list(solution[0]))\n",
    "            sum_transcript.at[main_df.index[row-1],'{} Summary num quarter'.format(col)]=' '.join(list(solution[1]))\n",
    "            sum_transcript.at[main_df.index[row-1],'{} Summary previous quarter'.format(col)]=' '.join(list(solution[3]))\n",
    "            sum_transcript.at[main_df.index[row-1],'{} Summary num previous quarter'.format(col)]=' '.join(list(solution[2]))\n",
    "             \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_transcript=sum_transcript.drop(columns=main_df.columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IUS.XX9 Summary quarter</th>\n",
       "      <th>IUS.XX9 Summary num quarter</th>\n",
       "      <th>IUS.XX9 Summary previous quarter</th>\n",
       "      <th>IUS.XX9 Summary num previous quarter</th>\n",
       "      <th>UNF Summary quarter</th>\n",
       "      <th>UNF Summary num quarter</th>\n",
       "      <th>UNF Summary previous quarter</th>\n",
       "      <th>UNF Summary num previous quarter</th>\n",
       "      <th>VERU Summary quarter</th>\n",
       "      <th>VERU Summary num quarter</th>\n",
       "      <th>...</th>\n",
       "      <th>532187 Summary previous quarter</th>\n",
       "      <th>532187 Summary num previous quarter</th>\n",
       "      <th>8905 Summary quarter</th>\n",
       "      <th>8905 Summary num quarter</th>\n",
       "      <th>8905 Summary previous quarter</th>\n",
       "      <th>8905 Summary num previous quarter</th>\n",
       "      <th>ABFLA Summary quarter</th>\n",
       "      <th>ABFLA Summary num quarter</th>\n",
       "      <th>ABFLA Summary previous quarter</th>\n",
       "      <th>ABFLA Summary num previous quarter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Q1 2017</td>\n",
       "      <td>sic like million the partial provid second mon...</td>\n",
       "      <td>391 33 43 4 9 114 1 313 2 7 363 57 8 16 358 69...</td>\n",
       "      <td>result like come million next rest second decr...</td>\n",
       "      <td>42 73 28 21 43 4 18 53 9 35 1 373 2 286 386 17...</td>\n",
       "      <td>sic like million the partial provid second mon...</td>\n",
       "      <td>391 33 43 4 9 114 1 313 2 7 363 57 8 16 358 69...</td>\n",
       "      <td>result like come million next rest second decr...</td>\n",
       "      <td>42 73 28 21 43 4 18 53 9 35 1 373 2 286 386 17...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rise come full expans space steadili incom hal...</td>\n",
       "      <td>22 5 12 8 21 11 141 4 9 14 7 6 31 3</td>\n",
       "      <td>million page annual high attend incom china ov...</td>\n",
       "      <td>22 5 35 12 1 8 28 71 11 500 900 0 63 7 6 9</td>\n",
       "      <td>fulli think kbw organiz kleinhanzl non phase e...</td>\n",
       "      <td>27 124 4 25 827 9 1 29 80 17 24 13 150 151 12 ...</td>\n",
       "      <td>lower happi discus million the regina session ...</td>\n",
       "      <td>448 28 30 21 623 9 1 29 539 100 17 981 14 7 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q2 2017</td>\n",
       "      <td>arrow plan result like million close futur sin...</td>\n",
       "      <td>367 30 4 49 9 68 312 1 80 2 2016 55 7 19 24 3 ...</td>\n",
       "      <td>record arrow result substanti provid second un...</td>\n",
       "      <td>0 4 9 114 313 2 2016 7 3 57 11 16 358 69 22 5 ...</td>\n",
       "      <td>arrow plan result like million close futur sin...</td>\n",
       "      <td>367 30 4 49 9 68 312 1 80 2 2016 55 7 19 24 3 ...</td>\n",
       "      <td>record arrow result substanti provid second un...</td>\n",
       "      <td>0 4 9 114 313 2 2016 7 3 57 11 16 358 69 22 5 ...</td>\n",
       "      <td>eastern discus the consid associ remark better...</td>\n",
       "      <td>800 46 03 21 4 18 02 49 53 9 35 10110602 570 2...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>result initi the digit page next annual doubl ...</td>\n",
       "      <td>211 8 33 2 6 19 4 18 7 32 9</td>\n",
       "      <td>oper store overview thi significantli announc ...</td>\n",
       "      <td>22 5 13 12 21 11 141 4 14 6 3</td>\n",
       "      <td>exampl result highlight underwrit stabl our te...</td>\n",
       "      <td>5 13 338 710 926 20 80 6 34 102 4 15 19 14 32 ...</td>\n",
       "      <td>think exist the rest strong pick still postag ...</td>\n",
       "      <td>27 21 4 9 200 20 1 80 2 17 7 569 13 12 168 8 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q3 2017</td>\n",
       "      <td>result like full term impair charg next unifir...</td>\n",
       "      <td>0 4 104 9 35 20 7 14 207 2017 363 364 403 41 5...</td>\n",
       "      <td>plan dilut the sintro month decreas unifirst n...</td>\n",
       "      <td>367 30 4 49 9 68 312 1 29 80 2 409 55 7 19 3 8...</td>\n",
       "      <td>result like full term impair charg next unifir...</td>\n",
       "      <td>0 4 104 9 35 20 7 14 207 2017 363 364 403 41 5...</td>\n",
       "      <td>plan dilut the sintro month decreas unifirst n...</td>\n",
       "      <td>367 30 4 49 9 68 312 1 29 80 2 409 55 7 19 3 8...</td>\n",
       "      <td>fc2 preboost back million close remark execut ...</td>\n",
       "      <td>42 30 01 47 4 25 26 06 2 7 3 000 2017 13 8 51 ...</td>\n",
       "      <td>...</td>\n",
       "      <td>_connector_ reason one that third</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>share join kbw punch the our page nanci regina...</td>\n",
       "      <td>5 1 29 28 2 16 14 59 24 26 9</td>\n",
       "      <td>think million our sandler regina vine remind n...</td>\n",
       "      <td>5 20 8 512 16 4 15 19 24 26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q4 2017</td>\n",
       "      <td>dilut think like full come our decreas unifirs...</td>\n",
       "      <td>28 47 0 9 374 65 1 373 2 2016 19 3 67 2017 13 ...</td>\n",
       "      <td>like full come the next unifirst anticip addit...</td>\n",
       "      <td>625 0 4 9 35 2 2016 7 14 24 207 3 2017 363 12 ...</td>\n",
       "      <td>dilut think like full come our decreas unifirs...</td>\n",
       "      <td>28 47 0 9 374 65 1 373 2 2016 19 3 67 2017 13 ...</td>\n",
       "      <td>like full come the next unifirst anticip addit...</td>\n",
       "      <td>625 0 4 9 35 2 2016 7 14 24 207 3 2017 363 12 ...</td>\n",
       "      <td>sheet preboost dilut break the remark beyond w...</td>\n",
       "      <td>5 12 8 944 1 56 2 2019 3 08 4 04 14 10116643 6...</td>\n",
       "      <td>...</td>\n",
       "      <td>result four doe that part there today much</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lower outsid the nanci regina vine chang remin...</td>\n",
       "      <td>5 800 12 1 8 30 54 75 16 4 19 23 17 6 53 9</td>\n",
       "      <td>fulli record join million full our higher outs...</td>\n",
       "      <td>2017 5 22 1 29 11 2 6 16 4 2016 25 7 14 350 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Q1 2018</td>\n",
       "      <td>like the remind second revis unifirst brief bu...</td>\n",
       "      <td>42 27 85 4 9 1 2 55 7 24 3 419 379 16 387 22 5...</td>\n",
       "      <td>sheet like million gener futur paid second ste...</td>\n",
       "      <td>46 28 0 4 9 374 1 373 2 19 67 8 5 415 56 34 38...</td>\n",
       "      <td>like the remind second revis unifirst brief bu...</td>\n",
       "      <td>42 27 85 4 9 1 2 55 7 24 3 419 379 16 387 22 5...</td>\n",
       "      <td>sheet like million gener futur paid second ste...</td>\n",
       "      <td>46 28 0 4 9 374 1 373 2 19 67 8 5 415 56 34 38...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>time mahesh due right base correct constraint ...</td>\n",
       "      <td>60 357 500 700 000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         IUS.XX9 Summary quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        sic like million the partial provid second mon...   \n",
       "Q2 2017        arrow plan result like million close futur sin...   \n",
       "Q3 2017        result like full term impair charg next unifir...   \n",
       "Q4 2017        dilut think like full come our decreas unifirs...   \n",
       "Q1 2018        like the remind second revis unifirst brief bu...   \n",
       "\n",
       "                                     IUS.XX9 Summary num quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        391 33 43 4 9 114 1 313 2 7 363 57 8 16 358 69...   \n",
       "Q2 2017        367 30 4 49 9 68 312 1 80 2 2016 55 7 19 24 3 ...   \n",
       "Q3 2017        0 4 104 9 35 20 7 14 207 2017 363 364 403 41 5...   \n",
       "Q4 2017        28 47 0 9 374 65 1 373 2 2016 19 3 67 2017 13 ...   \n",
       "Q1 2018        42 27 85 4 9 1 2 55 7 24 3 419 379 16 387 22 5...   \n",
       "\n",
       "                                IUS.XX9 Summary previous quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        result like come million next rest second decr...   \n",
       "Q2 2017        record arrow result substanti provid second un...   \n",
       "Q3 2017        plan dilut the sintro month decreas unifirst n...   \n",
       "Q4 2017        like full come the next unifirst anticip addit...   \n",
       "Q1 2018        sheet like million gener futur paid second ste...   \n",
       "\n",
       "                            IUS.XX9 Summary num previous quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        42 73 28 21 43 4 18 53 9 35 1 373 2 286 386 17...   \n",
       "Q2 2017        0 4 9 114 313 2 2016 7 3 57 11 16 358 69 22 5 ...   \n",
       "Q3 2017        367 30 4 49 9 68 312 1 29 80 2 409 55 7 19 3 8...   \n",
       "Q4 2017        625 0 4 9 35 2 2016 7 14 24 207 3 2017 363 12 ...   \n",
       "Q1 2018        46 28 0 4 9 374 1 373 2 19 67 8 5 415 56 34 38...   \n",
       "\n",
       "                                             UNF Summary quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        sic like million the partial provid second mon...   \n",
       "Q2 2017        arrow plan result like million close futur sin...   \n",
       "Q3 2017        result like full term impair charg next unifir...   \n",
       "Q4 2017        dilut think like full come our decreas unifirs...   \n",
       "Q1 2018        like the remind second revis unifirst brief bu...   \n",
       "\n",
       "                                         UNF Summary num quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        391 33 43 4 9 114 1 313 2 7 363 57 8 16 358 69...   \n",
       "Q2 2017        367 30 4 49 9 68 312 1 80 2 2016 55 7 19 24 3 ...   \n",
       "Q3 2017        0 4 104 9 35 20 7 14 207 2017 363 364 403 41 5...   \n",
       "Q4 2017        28 47 0 9 374 65 1 373 2 2016 19 3 67 2017 13 ...   \n",
       "Q1 2018        42 27 85 4 9 1 2 55 7 24 3 419 379 16 387 22 5...   \n",
       "\n",
       "                                    UNF Summary previous quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        result like come million next rest second decr...   \n",
       "Q2 2017        record arrow result substanti provid second un...   \n",
       "Q3 2017        plan dilut the sintro month decreas unifirst n...   \n",
       "Q4 2017        like full come the next unifirst anticip addit...   \n",
       "Q1 2018        sheet like million gener futur paid second ste...   \n",
       "\n",
       "                                UNF Summary num previous quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        42 73 28 21 43 4 18 53 9 35 1 373 2 286 386 17...   \n",
       "Q2 2017        0 4 9 114 313 2 2016 7 3 57 11 16 358 69 22 5 ...   \n",
       "Q3 2017        367 30 4 49 9 68 312 1 29 80 2 409 55 7 19 3 8...   \n",
       "Q4 2017        625 0 4 9 35 2 2016 7 14 24 207 3 2017 363 12 ...   \n",
       "Q1 2018        46 28 0 4 9 374 1 373 2 19 67 8 5 415 56 34 38...   \n",
       "\n",
       "                                            VERU Summary quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017                                                      NaN   \n",
       "Q2 2017        eastern discus the consid associ remark better...   \n",
       "Q3 2017        fc2 preboost back million close remark execut ...   \n",
       "Q4 2017        sheet preboost dilut break the remark beyond w...   \n",
       "Q1 2018                                                      NaN   \n",
       "\n",
       "                                        VERU Summary num quarter  ...  \\\n",
       "article_title                                                     ...   \n",
       "Q1 2017                                                      NaN  ...   \n",
       "Q2 2017        800 46 03 21 4 18 02 49 53 9 35 10110602 570 2...  ...   \n",
       "Q3 2017        42 30 01 47 4 25 26 06 2 7 3 000 2017 13 8 51 ...  ...   \n",
       "Q4 2017        5 12 8 944 1 56 2 2019 3 08 4 04 14 10116643 6...  ...   \n",
       "Q1 2018                                                      NaN  ...   \n",
       "\n",
       "                                 532187 Summary previous quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017                                                      NaN   \n",
       "Q2 2017                                                      NaN   \n",
       "Q3 2017                        _connector_ reason one that third   \n",
       "Q4 2017               result four doe that part there today much   \n",
       "Q1 2018        time mahesh due right base correct constraint ...   \n",
       "\n",
       "              532187 Summary num previous quarter  \\\n",
       "article_title                                       \n",
       "Q1 2017                                       NaN   \n",
       "Q2 2017                                       NaN   \n",
       "Q3 2017                                             \n",
       "Q4 2017                                             \n",
       "Q1 2018                        60 357 500 700 000   \n",
       "\n",
       "                                            8905 Summary quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        rise come full expans space steadili incom hal...   \n",
       "Q2 2017        result initi the digit page next annual doubl ...   \n",
       "Q3 2017                                                      NaN   \n",
       "Q4 2017                                                      NaN   \n",
       "Q1 2018                                                      NaN   \n",
       "\n",
       "                          8905 Summary num quarter  \\\n",
       "article_title                                        \n",
       "Q1 2017        22 5 12 8 21 11 141 4 9 14 7 6 31 3   \n",
       "Q2 2017                211 8 33 2 6 19 4 18 7 32 9   \n",
       "Q3 2017                                        NaN   \n",
       "Q4 2017                                        NaN   \n",
       "Q1 2018                                        NaN   \n",
       "\n",
       "                                   8905 Summary previous quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        million page annual high attend incom china ov...   \n",
       "Q2 2017        oper store overview thi significantli announc ...   \n",
       "Q3 2017                                                      NaN   \n",
       "Q4 2017                                                      NaN   \n",
       "Q1 2018                                                      NaN   \n",
       "\n",
       "                        8905 Summary num previous quarter  \\\n",
       "article_title                                               \n",
       "Q1 2017        22 5 35 12 1 8 28 71 11 500 900 0 63 7 6 9   \n",
       "Q2 2017                     22 5 13 12 21 11 141 4 14 6 3   \n",
       "Q3 2017                                               NaN   \n",
       "Q4 2017                                               NaN   \n",
       "Q1 2018                                               NaN   \n",
       "\n",
       "                                           ABFLA Summary quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        fulli think kbw organiz kleinhanzl non phase e...   \n",
       "Q2 2017        exampl result highlight underwrit stabl our te...   \n",
       "Q3 2017        share join kbw punch the our page nanci regina...   \n",
       "Q4 2017        lower outsid the nanci regina vine chang remin...   \n",
       "Q1 2018                                                      NaN   \n",
       "\n",
       "                                       ABFLA Summary num quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        27 124 4 25 827 9 1 29 80 17 24 13 150 151 12 ...   \n",
       "Q2 2017        5 13 338 710 926 20 80 6 34 102 4 15 19 14 32 ...   \n",
       "Q3 2017                             5 1 29 28 2 16 14 59 24 26 9   \n",
       "Q4 2017               5 800 12 1 8 30 54 75 16 4 19 23 17 6 53 9   \n",
       "Q1 2018                                                      NaN   \n",
       "\n",
       "                                  ABFLA Summary previous quarter  \\\n",
       "article_title                                                      \n",
       "Q1 2017        lower happi discus million the regina session ...   \n",
       "Q2 2017        think exist the rest strong pick still postag ...   \n",
       "Q3 2017        think million our sandler regina vine remind n...   \n",
       "Q4 2017        fulli record join million full our higher outs...   \n",
       "Q1 2018                                                      NaN   \n",
       "\n",
       "                              ABFLA Summary num previous quarter  \n",
       "article_title                                                     \n",
       "Q1 2017        448 28 30 21 623 9 1 29 539 100 17 981 14 7 18...  \n",
       "Q2 2017        27 21 4 9 200 20 1 80 2 17 7 569 13 12 168 8 1...  \n",
       "Q3 2017                              5 20 8 512 16 4 15 19 24 26  \n",
       "Q4 2017        2017 5 22 1 29 11 2 6 16 4 2016 25 7 14 350 20...  \n",
       "Q1 2018                                                      NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_transcript.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Summary_transcript.pickle', 'wb') as f:\n",
    "    pickle.dump(sum_transcript, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  \n",
    "# TOPIC MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have an insight of the difference between adjacent quarters, I want to know what are the main topics of each transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"mypickle.pickle\", \"rb\") as f:\n",
    "    fs2018 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to get the four main topics with the 20 most relevant words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 4\n",
    "n_top_words = 20\n",
    "dic={}\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "   \n",
    "        dic[topic_idx]=\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I personalize my list of stopwords.\n",
    "And I use two methods to get to the main topics:\n",
    "    1) Count Vectorizer\n",
    "    2) Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.9, max_features=1000, min_df=2,\n",
       "                ngram_range=(1, 1), preprocessor=None,\n",
       "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_stops = stopwords.words('english')\n",
    "my_stops = my_stops + ['ahead', 'youre', 'weve', 'yeah', 'hi', 'hey', 'im', 'youve', 'theres', 'indiscernible',\\\n",
    "                      'thats', 'theyre', 'please', 'operator', 'glenn', 'officer', 'executive', 'vice', 'president',\\\n",
    "                       'mayo', 'morning']\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=2, stop_words=my_stops, max_features=n_features, ngram_range=(1,2))\n",
    "cv_vectorizer = CountVectorizer(max_df=0.9, min_df=2, stop_words=my_stops, max_features=n_features)\n",
    "tfidf_vectorizer \n",
    "cv_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df=pd.DataFrame()\n",
    "tfidf_df=pd.DataFrame()\n",
    "\n",
    "quarters=[ 'Q1 2017',\n",
    "            'Q2 2017',\n",
    "            'Q3 2017',\n",
    "            'Q4 2017',\n",
    "            'Q1 2018',\n",
    "            'Q2 2018',\n",
    "            'Q3 2018',\n",
    "            'Q4 2018']\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "for col in main_df.columns:\n",
    "    for row in range(0,main_df.shape[0]):\n",
    "        \n",
    "        if pd.isnull(main_df[col][row])==False :\n",
    "  \n",
    "             tfidf = tfidf_vectorizer.fit_transform(sent_tokenize(fs2018['article_text'][row]))\n",
    "             cv = cv_vectorizer.fit_transform(sent_tokenize(fs2018['article_text'][row]))\n",
    "             nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5)\n",
    "             topic_vectors = nmf.fit_transform(cv)\n",
    "        \n",
    "        \n",
    "\n",
    "             cvdic={}\n",
    "             tfidfdic={}\n",
    "            \n",
    "             \n",
    "             cv_feature_names = cv_vectorizer.get_feature_names()\n",
    "             cvdic=print_top_words(nmf, cv_feature_names, n_top_words)\n",
    "             cv_df['{} {}'.format(col,quarters[row])]=list(dic.values())\n",
    "            \n",
    "            \n",
    "             tfidf_feature_names = tfidf_vectorizer.get_feature_names()   \n",
    "             tfidfdic=print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "             tfidf_df['{} {}'.format(col,quarters[row])]=list(dic.values())\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IUS.XX9 Q1 2017</th>\n",
       "      <th>IUS.XX9 Q2 2017</th>\n",
       "      <th>IUS.XX9 Q3 2017</th>\n",
       "      <th>IUS.XX9 Q4 2017</th>\n",
       "      <th>IUS.XX9 Q1 2018</th>\n",
       "      <th>IUS.XX9 Q2 2018</th>\n",
       "      <th>UNF Q1 2017</th>\n",
       "      <th>UNF Q2 2017</th>\n",
       "      <th>UNF Q3 2017</th>\n",
       "      <th>UNF Q4 2017</th>\n",
       "      <th>UNF Q1 2018</th>\n",
       "      <th>UNF Q2 2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>quarter million first income fiscal revenues o...</td>\n",
       "      <td>quarter million first income fiscal revenues o...</td>\n",
       "      <td>million year prior net 2017 september 30 compa...</td>\n",
       "      <td>year period focus micro hpe software half six ...</td>\n",
       "      <td>million quarter first sale 2018 2017 fourth co...</td>\n",
       "      <td>sek year million last compared quarter cash fl...</td>\n",
       "      <td>quarter million first income fiscal revenues o...</td>\n",
       "      <td>quarter million first income fiscal revenues o...</td>\n",
       "      <td>million year prior net 2017 september 30 compa...</td>\n",
       "      <td>year period focus micro hpe software half six ...</td>\n",
       "      <td>million quarter first sale 2018 2017 fourth co...</td>\n",
       "      <td>sek year million last compared quarter cash fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>think going side people sort saying us busines...</td>\n",
       "      <td>think going side people sort saying us busines...</td>\n",
       "      <td>nursing men term care tamsulosin capsules rele...</td>\n",
       "      <td>debt net adjusted number ebitda million times ...</td>\n",
       "      <td>astellia exfo share financial result 2018 loss...</td>\n",
       "      <td>services advanced also products course smb mar...</td>\n",
       "      <td>think going side people sort saying us busines...</td>\n",
       "      <td>think going side people sort saying us busines...</td>\n",
       "      <td>nursing men term care tamsulosin capsules rele...</td>\n",
       "      <td>debt net adjusted number ebitda million times ...</td>\n",
       "      <td>astellia exfo share financial result 2018 loss...</td>\n",
       "      <td>services advanced also products course smb mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tax fiscal rate benefit reform 2018 expect asu...</td>\n",
       "      <td>tax fiscal rate benefit reform 2018 expect asu...</td>\n",
       "      <td>company risks related development results deve...</td>\n",
       "      <td>months 12 october revenue going 2017 look like...</td>\n",
       "      <td>year yenista optics well expenses million doll...</td>\n",
       "      <td>margin volume see bit would focus gross say th...</td>\n",
       "      <td>tax fiscal rate benefit reform 2018 expect asu...</td>\n",
       "      <td>tax fiscal rate benefit reform 2018 expect asu...</td>\n",
       "      <td>company risks related development results deve...</td>\n",
       "      <td>months 12 october revenue going 2017 look like...</td>\n",
       "      <td>year yenista optics well expenses million doll...</td>\n",
       "      <td>margin volume see bit would focus gross say th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>year little compared bit ago last third first ...</td>\n",
       "      <td>year little compared bit ago last third first ...</td>\n",
       "      <td>prostate cancer clinical veru oral therapies r...</td>\n",
       "      <td>business one software really think management ...</td>\n",
       "      <td>fiber gig deployment good business high 100 ge...</td>\n",
       "      <td>segment sales growth slide organic smb result ...</td>\n",
       "      <td>year little compared bit ago last third first ...</td>\n",
       "      <td>year little compared bit ago last third first ...</td>\n",
       "      <td>prostate cancer clinical veru oral therapies r...</td>\n",
       "      <td>business one software really think management ...</td>\n",
       "      <td>fiber gig deployment good business high 100 ge...</td>\n",
       "      <td>segment sales growth slide organic smb result ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     IUS.XX9 Q1 2017  \\\n",
       "0  quarter million first income fiscal revenues o...   \n",
       "1  think going side people sort saying us busines...   \n",
       "2  tax fiscal rate benefit reform 2018 expect asu...   \n",
       "3  year little compared bit ago last third first ...   \n",
       "\n",
       "                                     IUS.XX9 Q2 2017  \\\n",
       "0  quarter million first income fiscal revenues o...   \n",
       "1  think going side people sort saying us busines...   \n",
       "2  tax fiscal rate benefit reform 2018 expect asu...   \n",
       "3  year little compared bit ago last third first ...   \n",
       "\n",
       "                                     IUS.XX9 Q3 2017  \\\n",
       "0  million year prior net 2017 september 30 compa...   \n",
       "1  nursing men term care tamsulosin capsules rele...   \n",
       "2  company risks related development results deve...   \n",
       "3  prostate cancer clinical veru oral therapies r...   \n",
       "\n",
       "                                     IUS.XX9 Q4 2017  \\\n",
       "0  year period focus micro hpe software half six ...   \n",
       "1  debt net adjusted number ebitda million times ...   \n",
       "2  months 12 october revenue going 2017 look like...   \n",
       "3  business one software really think management ...   \n",
       "\n",
       "                                     IUS.XX9 Q1 2018  \\\n",
       "0  million quarter first sale 2018 2017 fourth co...   \n",
       "1  astellia exfo share financial result 2018 loss...   \n",
       "2  year yenista optics well expenses million doll...   \n",
       "3  fiber gig deployment good business high 100 ge...   \n",
       "\n",
       "                                     IUS.XX9 Q2 2018  \\\n",
       "0  sek year million last compared quarter cash fl...   \n",
       "1  services advanced also products course smb mar...   \n",
       "2  margin volume see bit would focus gross say th...   \n",
       "3  segment sales growth slide organic smb result ...   \n",
       "\n",
       "                                         UNF Q1 2017  \\\n",
       "0  quarter million first income fiscal revenues o...   \n",
       "1  think going side people sort saying us busines...   \n",
       "2  tax fiscal rate benefit reform 2018 expect asu...   \n",
       "3  year little compared bit ago last third first ...   \n",
       "\n",
       "                                         UNF Q2 2017  \\\n",
       "0  quarter million first income fiscal revenues o...   \n",
       "1  think going side people sort saying us busines...   \n",
       "2  tax fiscal rate benefit reform 2018 expect asu...   \n",
       "3  year little compared bit ago last third first ...   \n",
       "\n",
       "                                         UNF Q3 2017  \\\n",
       "0  million year prior net 2017 september 30 compa...   \n",
       "1  nursing men term care tamsulosin capsules rele...   \n",
       "2  company risks related development results deve...   \n",
       "3  prostate cancer clinical veru oral therapies r...   \n",
       "\n",
       "                                         UNF Q4 2017  \\\n",
       "0  year period focus micro hpe software half six ...   \n",
       "1  debt net adjusted number ebitda million times ...   \n",
       "2  months 12 october revenue going 2017 look like...   \n",
       "3  business one software really think management ...   \n",
       "\n",
       "                                         UNF Q1 2018  \\\n",
       "0  million quarter first sale 2018 2017 fourth co...   \n",
       "1  astellia exfo share financial result 2018 loss...   \n",
       "2  year yenista optics well expenses million doll...   \n",
       "3  fiber gig deployment good business high 100 ge...   \n",
       "\n",
       "                                         UNF Q2 2018  \n",
       "0  sek year million last compared quarter cash fl...  \n",
       "1  services advanced also products course smb mar...  \n",
       "2  margin volume see bit would focus gross say th...  \n",
       "3  segment sales growth slide organic smb result ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IUS.XX9 Q1 2017</th>\n",
       "      <th>IUS.XX9 Q2 2017</th>\n",
       "      <th>IUS.XX9 Q3 2017</th>\n",
       "      <th>IUS.XX9 Q4 2017</th>\n",
       "      <th>IUS.XX9 Q1 2018</th>\n",
       "      <th>IUS.XX9 Q2 2018</th>\n",
       "      <th>UNF Q1 2017</th>\n",
       "      <th>UNF Q2 2017</th>\n",
       "      <th>UNF Q3 2017</th>\n",
       "      <th>UNF Q4 2017</th>\n",
       "      <th>UNF Q1 2018</th>\n",
       "      <th>UNF Q2 2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>margin honest difficult far diluted next quest...</td>\n",
       "      <td>margin honest difficult far diluted next quest...</td>\n",
       "      <td>get much prescription launch keep going start ...</td>\n",
       "      <td>product innovation debt provision go detail en...</td>\n",
       "      <td>foreign exchange interconnect credit facility ...</td>\n",
       "      <td>november remember improved good cash margin ba...</td>\n",
       "      <td>margin honest difficult far diluted next quest...</td>\n",
       "      <td>margin honest difficult far diluted next quest...</td>\n",
       "      <td>get much prescription launch keep going start ...</td>\n",
       "      <td>product innovation debt provision go detail en...</td>\n",
       "      <td>foreign exchange interconnect credit facility ...</td>\n",
       "      <td>november remember improved good cash margin ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>prior year environmental outstanding like part...</td>\n",
       "      <td>prior year environmental outstanding like part...</td>\n",
       "      <td>granule formulation future operating back dr n...</td>\n",
       "      <td>committed guidance range 842 million helps us ...</td>\n",
       "      <td>also continued margins credit let 19 million f...</td>\n",
       "      <td>offering activities advanced managed conclude ...</td>\n",
       "      <td>prior year environmental outstanding like part...</td>\n",
       "      <td>prior year environmental outstanding like part...</td>\n",
       "      <td>granule formulation future operating back dr n...</td>\n",
       "      <td>committed guidance range 842 million helps us ...</td>\n",
       "      <td>also continued margins credit let 19 million f...</td>\n",
       "      <td>offering activities advanced managed conclude ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pretty diluted mean asu million reported 2016 ...</td>\n",
       "      <td>pretty diluted mean asu million reported 2016 ...</td>\n",
       "      <td>biopharmaceutical marketing looked capsules al...</td>\n",
       "      <td>got take 12 heritage micro mainframe dividend ...</td>\n",
       "      <td>overall part gross margins optics continuing f...</td>\n",
       "      <td>higher margins quite nordic b2b relation credi...</td>\n",
       "      <td>pretty diluted mean asu million reported 2016 ...</td>\n",
       "      <td>pretty diluted mean asu million reported 2016 ...</td>\n",
       "      <td>biopharmaceutical marketing looked capsules al...</td>\n",
       "      <td>got take 12 heritage micro mainframe dividend ...</td>\n",
       "      <td>overall part gross margins optics continuing f...</td>\n",
       "      <td>higher margins quite nordic b2b relation credi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>really future results caution balance addition...</td>\n",
       "      <td>really future results caution balance addition...</td>\n",
       "      <td>last associated better pipeline growth opportu...</td>\n",
       "      <td>beginning hewlett packard month let organizati...</td>\n",
       "      <td>cost decrease company deployment announcements...</td>\n",
       "      <td>norriq new ended sek organic let organizations...</td>\n",
       "      <td>really future results caution balance addition...</td>\n",
       "      <td>really future results caution balance addition...</td>\n",
       "      <td>last associated better pipeline growth opportu...</td>\n",
       "      <td>beginning hewlett packard month let organizati...</td>\n",
       "      <td>cost decrease company deployment announcements...</td>\n",
       "      <td>norriq new ended sek organic let organizations...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     IUS.XX9 Q1 2017  \\\n",
       "0  margin honest difficult far diluted next quest...   \n",
       "1  prior year environmental outstanding like part...   \n",
       "2  pretty diluted mean asu million reported 2016 ...   \n",
       "3  really future results caution balance addition...   \n",
       "\n",
       "                                     IUS.XX9 Q2 2017  \\\n",
       "0  margin honest difficult far diluted next quest...   \n",
       "1  prior year environmental outstanding like part...   \n",
       "2  pretty diluted mean asu million reported 2016 ...   \n",
       "3  really future results caution balance addition...   \n",
       "\n",
       "                                     IUS.XX9 Q3 2017  \\\n",
       "0  get much prescription launch keep going start ...   \n",
       "1  granule formulation future operating back dr n...   \n",
       "2  biopharmaceutical marketing looked capsules al...   \n",
       "3  last associated better pipeline growth opportu...   \n",
       "\n",
       "                                     IUS.XX9 Q4 2017  \\\n",
       "0  product innovation debt provision go detail en...   \n",
       "1  committed guidance range 842 million helps us ...   \n",
       "2  got take 12 heritage micro mainframe dividend ...   \n",
       "3  beginning hewlett packard month let organizati...   \n",
       "\n",
       "                                     IUS.XX9 Q1 2018  \\\n",
       "0  foreign exchange interconnect credit facility ...   \n",
       "1  also continued margins credit let 19 million f...   \n",
       "2  overall part gross margins optics continuing f...   \n",
       "3  cost decrease company deployment announcements...   \n",
       "\n",
       "                                     IUS.XX9 Q2 2018  \\\n",
       "0  november remember improved good cash margin ba...   \n",
       "1  offering activities advanced managed conclude ...   \n",
       "2  higher margins quite nordic b2b relation credi...   \n",
       "3  norriq new ended sek organic let organizations...   \n",
       "\n",
       "                                         UNF Q1 2017  \\\n",
       "0  margin honest difficult far diluted next quest...   \n",
       "1  prior year environmental outstanding like part...   \n",
       "2  pretty diluted mean asu million reported 2016 ...   \n",
       "3  really future results caution balance addition...   \n",
       "\n",
       "                                         UNF Q2 2017  \\\n",
       "0  margin honest difficult far diluted next quest...   \n",
       "1  prior year environmental outstanding like part...   \n",
       "2  pretty diluted mean asu million reported 2016 ...   \n",
       "3  really future results caution balance addition...   \n",
       "\n",
       "                                         UNF Q3 2017  \\\n",
       "0  get much prescription launch keep going start ...   \n",
       "1  granule formulation future operating back dr n...   \n",
       "2  biopharmaceutical marketing looked capsules al...   \n",
       "3  last associated better pipeline growth opportu...   \n",
       "\n",
       "                                         UNF Q4 2017  \\\n",
       "0  product innovation debt provision go detail en...   \n",
       "1  committed guidance range 842 million helps us ...   \n",
       "2  got take 12 heritage micro mainframe dividend ...   \n",
       "3  beginning hewlett packard month let organizati...   \n",
       "\n",
       "                                         UNF Q1 2018  \\\n",
       "0  foreign exchange interconnect credit facility ...   \n",
       "1  also continued margins credit let 19 million f...   \n",
       "2  overall part gross margins optics continuing f...   \n",
       "3  cost decrease company deployment announcements...   \n",
       "\n",
       "                                         UNF Q2 2018  \n",
       "0  november remember improved good cash margin ba...  \n",
       "1  offering activities advanced managed conclude ...  \n",
       "2  higher margins quite nordic b2b relation credi...  \n",
       "3  norriq new ended sek organic let organizations...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analyser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Positive/Negative words with Mcdonald Loughran lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mypickle.pickle\", \"rb\") as f:\n",
    "    fs2018 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_file(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = read_list_from_file('LM_Positive.txt')\n",
    "neg_list = read_list_from_file('LM_Negative.txt')\n",
    "\n",
    "for word in pos_list:\n",
    "    pos_keyword_processor.add_keyword(word)\n",
    "for word in neg_list:\n",
    "    neg_keyword_processor.add_keyword(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "\n",
    "positive_words = set(pos_list)\n",
    "negative_words = set(neg_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 methods to count positive and negative words for each transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pos_neg(df):\n",
    "    df['Tokenized'] = df['article_text'].apply(str.lower).apply(word_tokenize)\n",
    "    df['WordCount'] = df['Tokenized'].apply(lambda x: Counter(x))\n",
    "\n",
    "    df['Positive'] = df['WordCount'].apply(lambda x: sum(v for k,v in x.items() if k in positive_words))\n",
    "    df['Negative'] = df['WordCount'].apply(lambda x: sum(v for k,v in x.items() if k in negative_words))\n",
    "    return df\n",
    "\n",
    "def count_pos_neg_flash(df):\n",
    "    #df['Tokenized'] = df['article_text'].apply(str.lower).apply(word_tokenize)\n",
    "    #df['WordCount'] = df['Tokenized'].apply(lambda x: Counter(x))\n",
    "\n",
    "    df['Positive'] = df['article_text'].apply(lambda x: len(pos_keyword_processor.extract_keywords(x)))\n",
    "    df['Negative'] = df['article_text'].apply(lambda x: len(neg_keyword_processor.extract_keywords(x)))\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32min 51s\n"
     ]
    }
   ],
   "source": [
    "%time fs2018 = count_pos_neg_flash(fs2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I calculate the sentiment score between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs2018['LM Score']=(fs2018['Positive']-fs2018['Negative'])/fs2018['Positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€œValence Aware Dictionary and sEntiment Reasonerâ€ is another popular rule-based library for sentiment analysis. Like TextBlob, it uses a sentiment lexicon that contains intensity measures for each word based on human-annotated labels. A key difference however, is that VADER was designed with a focus on social media texts. This means that it puts a lot of emphasis on rules that capture the essence of text typically seen on social media â€” for example, short sentences with emojis, repetitive vocabulary and copious use of punctuation (such as exclamation marks). \n",
    "\n",
    "In my case it is not the most appropriate method but I still want to use it to check if it can give me good result anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Ilan\n",
      "[nltk_data]     avraham\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "fs2018['Vader'] = fs2018['article_text'].apply(lambda x:analyzer.polarity_scores(x)['compound'])   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextBlob is a popular Python library for processing textual data. It is built on top of NLTK, another popular Natural Language Processing toolbox for Python. TextBlob uses a sentiment lexicon (consisting of predefined words) to assign scores for each word, which are then averaged out using a weighted average to give an overall sentence sentiment score. Three scores: â€œpolarityâ€, â€œsubjectivityâ€ and â€œintensityâ€ are calculated for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "fs2018['TextBlob'] = fs2018['article_text'].apply(str.lower).apply(lambda x:TextBlob(x).sentiment.polarity)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>article_date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_source</th>\n",
       "      <th>article_text</th>\n",
       "      <th>article_title</th>\n",
       "      <th>organization_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>LM Score</th>\n",
       "      <th>Vader</th>\n",
       "      <th>TextBlob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>IUS.XX9</td>\n",
       "      <td>2018-01-03 15:00:00|2018-01-03 15:53:05</td>\n",
       "      <td>2026528</td>\n",
       "      <td>Q1 2018 Earnings Call - 2026528 : 904708104</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>Q1 2018 Earnings Call</td>\n",
       "      <td>UniFirst Corp.</td>\n",
       "      <td>US:IUS.XX9</td>\n",
       "      <td>74</td>\n",
       "      <td>37</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.138270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>UNF</td>\n",
       "      <td>2018-01-03 15:00:00|2018-01-03 15:53:05</td>\n",
       "      <td>2026528</td>\n",
       "      <td>Q1 2018 Earnings Call - 2026528 : 904708104</td>\n",
       "      <td>ALL TEXT IS RELEVANT Ladies gentlemen, thank s...</td>\n",
       "      <td>Q1 2018 Earnings Call</td>\n",
       "      <td>UniFirst Corp.</td>\n",
       "      <td>US:UNF</td>\n",
       "      <td>74</td>\n",
       "      <td>37</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.138270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>VERU</td>\n",
       "      <td>2018-01-05 13:00:00|2018-01-05 21:23:05</td>\n",
       "      <td>2029277</td>\n",
       "      <td>Q4 2017 Earnings Call - 2029277 : 92536C103</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning, ladies gent...</td>\n",
       "      <td>Q4 2017 Earnings Call</td>\n",
       "      <td>Veru, Inc.</td>\n",
       "      <td>US:VERU</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>-0.060606</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.085348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>GB</td>\n",
       "      <td>MCRO</td>\n",
       "      <td>2018-01-08 09:00:00|2018-01-08 10:48:49</td>\n",
       "      <td>2021320</td>\n",
       "      <td>Q2 2018 Earnings Call - 2021320 : G6117L186</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good morning everyone wel...</td>\n",
       "      <td>Q2 2018 Earnings Call</td>\n",
       "      <td>Micro Focus International Plc</td>\n",
       "      <td>GB:MCRO</td>\n",
       "      <td>107</td>\n",
       "      <td>66</td>\n",
       "      <td>0.383178</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.119395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CA</td>\n",
       "      <td>EXF</td>\n",
       "      <td>2018-01-09 22:00:00|2018-01-09 23:42:39</td>\n",
       "      <td>2024627</td>\n",
       "      <td>Q1 2018 Earnings Call - 2024627 : 302046107</td>\n",
       "      <td>ALL TEXT IS RELEVANT Good day welcome EXFO's F...</td>\n",
       "      <td>Q1 2018 Earnings Call</td>\n",
       "      <td>EXFO, Inc.</td>\n",
       "      <td>CA:EXF</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.145621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Indicator   Ticker                             article_date  article_id  \\\n",
       "0        US  IUS.XX9  2018-01-03 15:00:00|2018-01-03 15:53:05     2026528   \n",
       "1        US      UNF  2018-01-03 15:00:00|2018-01-03 15:53:05     2026528   \n",
       "2        US     VERU  2018-01-05 13:00:00|2018-01-05 21:23:05     2029277   \n",
       "3        GB     MCRO  2018-01-08 09:00:00|2018-01-08 10:48:49     2021320   \n",
       "4        CA      EXF  2018-01-09 22:00:00|2018-01-09 23:42:39     2024627   \n",
       "\n",
       "                                article_source  \\\n",
       "0  Q1 2018 Earnings Call - 2026528 : 904708104   \n",
       "1  Q1 2018 Earnings Call - 2026528 : 904708104   \n",
       "2  Q4 2017 Earnings Call - 2029277 : 92536C103   \n",
       "3  Q2 2018 Earnings Call - 2021320 : G6117L186   \n",
       "4  Q1 2018 Earnings Call - 2024627 : 302046107   \n",
       "\n",
       "                                        article_text          article_title  \\\n",
       "0  ALL TEXT IS RELEVANT Ladies gentlemen, thank s...  Q1 2018 Earnings Call   \n",
       "1  ALL TEXT IS RELEVANT Ladies gentlemen, thank s...  Q1 2018 Earnings Call   \n",
       "2  ALL TEXT IS RELEVANT Good morning, ladies gent...  Q4 2017 Earnings Call   \n",
       "3  ALL TEXT IS RELEVANT Good morning everyone wel...  Q2 2018 Earnings Call   \n",
       "4  ALL TEXT IS RELEVANT Good day welcome EXFO's F...  Q1 2018 Earnings Call   \n",
       "\n",
       "               organization_name      ticker  Positive  Negative  LM Score  \\\n",
       "0                 UniFirst Corp.  US:IUS.XX9        74        37  0.500000   \n",
       "1                 UniFirst Corp.      US:UNF        74        37  0.500000   \n",
       "2                     Veru, Inc.     US:VERU        66        70 -0.060606   \n",
       "3  Micro Focus International Plc     GB:MCRO       107        66  0.383178   \n",
       "4                     EXFO, Inc.      CA:EXF        57        25  0.561404   \n",
       "\n",
       "    Vader  TextBlob  \n",
       "0  0.9999  0.138270  \n",
       "1  0.9999  0.138270  \n",
       "2  0.9999  0.085348  \n",
       "3  1.0000  0.119395  \n",
       "4  0.9999  0.145621  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To go further, I wanted to get the return of each ticker after each transcript (take me too long to run the code so I abandon it)\n",
    "and check if there is a correlation between the sentiment score, by using supervised method of sentiment analysis where the return is the target.\n",
    "We can split the return into category to make it easier.\n",
    "After we use classification method (like Random forest, Neural Network..) to check the accuracy of our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
